input {
    kafka {
        bootstrap_servers => ["192.168.205.10:29092"]
        auto_offset_reset => "latest"
        topics => ["test"]
    }
}
filter {
    grok {
        match => [ "message", "^\[%{TIMESTAMP_ISO8601:logtime}\] \[%{LOGLEVEL:level}\] \[%{DATA:machine}\] %{GREEDYDATA:message}" ]
        overwrite => [ "message" ]
    }

    date {
       match => [ "logtime", "ISO8601" ]
       remove_field => ['logtime']
    }
}

output {
    stdout {
      codec => rubydebug { }
    }
    elasticsearch {
        action => "index"                #The operation on ES
        codec  => rubydebug
        hosts  => ["192.168.205.10:29200"]      #ElasticSearch host, can be array.
        index  => "logstash-%{+YYYY.MM.dd}"      #The index to write data to.
    }
}

